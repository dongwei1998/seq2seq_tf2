2022-05-22 18:45:38|INFO|train.py[:29]|Start loading data ...
2022-05-22 18:45:38|INFO|train.py[:31]|Data loading is complete, inp len 1000, targ len 1000, which takes 0.004002 s
2022-05-22 18:45:38|INFO|train.py[:37]|Loading text processor...
2022-05-22 18:46:14|INFO|train.py[:29]|Start loading data ...
2022-05-22 18:46:14|INFO|train.py[:31]|Data loading is complete, inp len 1000, targ len 1000, which takes 0.000000 s
2022-05-22 18:46:14|INFO|train.py[:37]|Loading text processor...
2022-05-22 18:46:22|INFO|train.py[:73]|epoch 1, batch 1, loss:4.4639
2022-05-22 18:46:25|INFO|train.py[:73]|epoch 1, batch 2, loss:4.5867
2022-05-22 18:46:27|INFO|train.py[:73]|epoch 1, batch 3, loss:4.6994
2022-05-22 18:46:30|INFO|train.py[:73]|epoch 1, batch 4, loss:4.6219
2022-05-22 18:46:33|INFO|train.py[:73]|epoch 1, batch 5, loss:4.5697
2022-05-22 18:46:36|INFO|train.py[:73]|epoch 1, batch 6, loss:4.5883
2022-05-22 18:46:39|INFO|train.py[:73]|epoch 1, batch 7, loss:4.4762
2022-05-22 18:46:41|INFO|train.py[:73]|epoch 1, batch 8, loss:4.2872
2022-05-22 18:46:44|INFO|train.py[:73]|epoch 1, batch 9, loss:4.0888
2022-05-22 18:46:47|INFO|train.py[:73]|epoch 1, batch 10, loss:3.8698
2022-05-22 18:46:50|INFO|train.py[:73]|epoch 1, batch 11, loss:3.2790
2022-05-22 18:46:53|INFO|train.py[:73]|epoch 1, batch 12, loss:3.6468
2022-05-22 18:46:55|INFO|train.py[:73]|epoch 1, batch 13, loss:3.6744
2022-05-22 18:46:58|INFO|train.py[:73]|epoch 1, batch 14, loss:2.8674
2022-05-22 18:47:01|INFO|train.py[:73]|epoch 1, batch 15, loss:3.0211
2022-05-22 18:47:04|INFO|train.py[:73]|epoch 1, batch 16, loss:3.0045
2022-05-22 18:47:06|INFO|train.py[:73]|epoch 1, batch 17, loss:3.2832
2022-05-22 18:47:09|INFO|train.py[:73]|epoch 1, batch 18, loss:3.0000
2022-05-22 18:47:12|INFO|train.py[:73]|epoch 1, batch 19, loss:2.8298
2022-05-22 18:47:15|INFO|train.py[:73]|epoch 1, batch 20, loss:2.9202
2022-05-22 18:47:17|INFO|train.py[:73]|epoch 1, batch 21, loss:2.8483
2022-05-22 18:47:20|INFO|train.py[:73]|epoch 1, batch 22, loss:2.8482
2022-05-22 18:47:23|INFO|train.py[:73]|epoch 1, batch 23, loss:3.0079
2022-05-22 18:47:26|INFO|train.py[:73]|epoch 1, batch 24, loss:2.7215
2022-05-22 18:47:28|INFO|train.py[:73]|epoch 1, batch 25, loss:2.7318
2022-05-22 18:47:31|INFO|train.py[:73]|epoch 1, batch 26, loss:2.6730
2022-05-22 18:47:34|INFO|train.py[:73]|epoch 1, batch 27, loss:3.2226
2022-05-22 18:47:37|INFO|train.py[:73]|epoch 1, batch 28, loss:3.0324
2022-05-22 18:47:39|INFO|train.py[:73]|epoch 1, batch 29, loss:2.8519
2022-05-22 18:47:42|INFO|train.py[:73]|epoch 1, batch 30, loss:2.9327
2022-05-22 18:47:45|INFO|train.py[:73]|epoch 1, batch 31, loss:2.5974
2022-05-22 18:47:48|INFO|train.py[:73]|epoch 1, batch 32, loss:2.9311
2022-05-22 18:47:51|INFO|train.py[:73]|epoch 1, batch 33, loss:2.9904
2022-05-22 18:47:54|INFO|train.py[:73]|epoch 1, batch 34, loss:2.6740
2022-05-22 18:47:56|INFO|train.py[:73]|epoch 1, batch 35, loss:2.6992
2022-05-22 18:47:59|INFO|train.py[:73]|epoch 1, batch 36, loss:2.8589
2022-05-22 18:48:02|INFO|train.py[:73]|epoch 1, batch 37, loss:2.7438
2022-05-22 18:48:04|INFO|train.py[:73]|epoch 1, batch 38, loss:2.4824
2022-05-22 18:48:07|INFO|train.py[:73]|epoch 1, batch 39, loss:2.9397
2022-05-22 18:48:10|INFO|train.py[:73]|epoch 1, batch 40, loss:2.5726
2022-05-22 18:48:13|INFO|train.py[:73]|epoch 1, batch 41, loss:2.6034
2022-05-22 18:48:15|INFO|train.py[:73]|epoch 1, batch 42, loss:2.5925
2022-05-22 18:48:18|INFO|train.py[:73]|epoch 1, batch 43, loss:2.7323
2022-05-22 18:48:21|INFO|train.py[:73]|epoch 1, batch 44, loss:2.9923
2022-05-22 18:48:24|INFO|train.py[:73]|epoch 1, batch 45, loss:2.6462
2022-05-22 18:48:26|INFO|train.py[:73]|epoch 1, batch 46, loss:2.6674
2022-05-22 18:48:29|INFO|train.py[:73]|epoch 1, batch 47, loss:3.0073
2022-05-22 18:48:32|INFO|train.py[:73]|epoch 1, batch 48, loss:2.6163
2022-05-22 18:48:35|INFO|train.py[:73]|epoch 1, batch 49, loss:2.5066
2022-05-22 18:48:37|INFO|train.py[:73]|epoch 1, batch 50, loss:2.4331
2022-05-22 18:48:40|INFO|train.py[:73]|epoch 1, batch 51, loss:2.6438
2022-05-22 18:48:43|INFO|train.py[:73]|epoch 1, batch 52, loss:2.5605
2022-05-22 18:48:46|INFO|train.py[:73]|epoch 1, batch 53, loss:2.5466
2022-05-22 18:48:48|INFO|train.py[:73]|epoch 1, batch 54, loss:2.7267
2022-05-22 18:48:51|INFO|train.py[:73]|epoch 1, batch 55, loss:3.1259
2022-05-22 18:48:54|INFO|train.py[:73]|epoch 1, batch 56, loss:3.2537
2022-05-22 18:48:56|INFO|train.py[:73]|epoch 1, batch 57, loss:3.0494
2022-05-22 18:48:59|INFO|train.py[:73]|epoch 1, batch 58, loss:2.9019
2022-05-22 18:49:02|INFO|train.py[:73]|epoch 1, batch 59, loss:3.1548
2022-05-22 18:49:05|INFO|train.py[:73]|epoch 1, batch 60, loss:2.8579
2022-05-22 18:49:07|INFO|train.py[:73]|epoch 1, batch 61, loss:2.5452
2022-05-22 18:49:10|INFO|train.py[:73]|epoch 1, batch 62, loss:2.8791
2022-05-22 18:49:13|INFO|train.py[:73]|epoch 1, batch 63, loss:2.8709
2022-05-22 18:49:13|INFO|train.py[:81]|epoch 1, batch 63, loss:3.1119
2022-05-22 18:49:16|INFO|train.py[:73]|epoch 2, batch 64, loss:2.7584
2022-05-22 18:49:18|INFO|train.py[:73]|epoch 2, batch 65, loss:2.4989
2022-05-22 18:49:21|INFO|train.py[:73]|epoch 2, batch 66, loss:2.3422
2022-05-22 18:49:24|INFO|train.py[:73]|epoch 2, batch 67, loss:2.7578
2022-05-22 18:49:27|INFO|train.py[:73]|epoch 2, batch 68, loss:2.3520
2022-05-22 18:49:29|INFO|train.py[:73]|epoch 2, batch 69, loss:2.1890
2022-05-22 18:49:32|INFO|train.py[:73]|epoch 2, batch 70, loss:2.2670
2022-05-22 18:49:35|INFO|train.py[:73]|epoch 2, batch 71, loss:2.4171
2022-05-22 18:49:38|INFO|train.py[:73]|epoch 2, batch 72, loss:2.3573
2022-05-22 18:49:40|INFO|train.py[:73]|epoch 2, batch 73, loss:2.4631
2022-05-22 18:49:43|INFO|train.py[:73]|epoch 2, batch 74, loss:2.3116
2022-05-22 18:49:46|INFO|train.py[:73]|epoch 2, batch 75, loss:2.3498
2022-05-22 18:49:49|INFO|train.py[:73]|epoch 2, batch 76, loss:2.6641
2022-05-22 18:49:52|INFO|train.py[:73]|epoch 2, batch 77, loss:2.1261
2022-05-22 18:49:54|INFO|train.py[:73]|epoch 2, batch 78, loss:2.3198
2022-05-22 18:49:57|INFO|train.py[:73]|epoch 2, batch 79, loss:2.3561
2022-05-22 18:50:00|INFO|train.py[:73]|epoch 2, batch 80, loss:2.7755
2022-05-22 18:50:03|INFO|train.py[:73]|epoch 2, batch 81, loss:2.4754
2022-05-22 18:50:05|INFO|train.py[:73]|epoch 2, batch 82, loss:2.2787
2022-05-22 18:50:08|INFO|train.py[:73]|epoch 2, batch 83, loss:2.2965
2022-05-22 18:50:11|INFO|train.py[:73]|epoch 2, batch 84, loss:2.3323
2022-05-22 18:50:14|INFO|train.py[:73]|epoch 2, batch 85, loss:2.2996
2022-05-22 18:50:16|INFO|train.py[:73]|epoch 2, batch 86, loss:2.5134
2022-05-22 18:50:19|INFO|train.py[:73]|epoch 2, batch 87, loss:2.3475
2022-05-22 18:50:22|INFO|train.py[:73]|epoch 2, batch 88, loss:2.2641
2022-05-22 18:50:25|INFO|train.py[:73]|epoch 2, batch 89, loss:2.1231
2022-05-22 18:50:27|INFO|train.py[:73]|epoch 2, batch 90, loss:2.8404
2022-05-22 18:50:30|INFO|train.py[:73]|epoch 2, batch 91, loss:2.6014
2022-05-22 18:50:33|INFO|train.py[:73]|epoch 2, batch 92, loss:2.1585
2022-05-22 18:50:36|INFO|train.py[:73]|epoch 2, batch 93, loss:2.4092
2022-05-22 18:50:38|INFO|train.py[:73]|epoch 2, batch 94, loss:2.2201
2022-05-22 18:50:41|INFO|train.py[:73]|epoch 2, batch 95, loss:2.6654
2022-05-22 18:50:44|INFO|train.py[:73]|epoch 2, batch 96, loss:2.7612
2022-05-22 18:50:47|INFO|train.py[:73]|epoch 2, batch 97, loss:2.2941
2022-05-22 18:50:49|INFO|train.py[:73]|epoch 2, batch 98, loss:2.3997
2022-05-22 18:50:52|INFO|train.py[:73]|epoch 2, batch 99, loss:2.4215
2022-05-22 18:50:55|INFO|train.py[:73]|epoch 2, batch 100, loss:2.3534
2022-05-22 18:50:58|INFO|train.py[:73]|epoch 2, batch 101, loss:2.2146
2022-05-22 18:51:00|INFO|train.py[:73]|epoch 2, batch 102, loss:2.6243
2022-05-22 18:51:03|INFO|train.py[:73]|epoch 2, batch 103, loss:2.5435
2022-05-22 18:51:06|INFO|train.py[:73]|epoch 2, batch 104, loss:2.4631
2022-05-22 18:51:09|INFO|train.py[:73]|epoch 2, batch 105, loss:2.3349
2022-05-22 18:51:11|INFO|train.py[:73]|epoch 2, batch 106, loss:2.3563
2022-05-22 18:51:14|INFO|train.py[:73]|epoch 2, batch 107, loss:2.4806
2022-05-22 18:51:17|INFO|train.py[:73]|epoch 2, batch 108, loss:2.2784
2022-05-22 18:51:19|INFO|train.py[:73]|epoch 2, batch 109, loss:2.4130
2022-05-22 18:51:22|INFO|train.py[:73]|epoch 2, batch 110, loss:2.6890
2022-05-22 18:51:25|INFO|train.py[:73]|epoch 2, batch 111, loss:2.3465
2022-05-22 18:51:28|INFO|train.py[:73]|epoch 2, batch 112, loss:2.1883
2022-05-22 18:51:30|INFO|train.py[:73]|epoch 2, batch 113, loss:2.0343
2022-05-22 18:51:33|INFO|train.py[:73]|epoch 2, batch 114, loss:2.3827
2022-05-22 18:51:36|INFO|train.py[:73]|epoch 2, batch 115, loss:2.2566
2022-05-22 18:51:38|INFO|train.py[:73]|epoch 2, batch 116, loss:2.2642
2022-05-22 18:51:41|INFO|train.py[:73]|epoch 2, batch 117, loss:2.4473
2022-05-22 18:51:44|INFO|train.py[:73]|epoch 2, batch 118, loss:2.7769
2022-05-22 18:51:46|INFO|train.py[:73]|epoch 2, batch 119, loss:2.6949
2022-05-22 18:51:49|INFO|train.py[:73]|epoch 2, batch 120, loss:2.7025
2022-05-22 18:51:52|INFO|train.py[:73]|epoch 2, batch 121, loss:2.5104
2022-05-22 18:51:55|INFO|train.py[:73]|epoch 2, batch 122, loss:2.7093
2022-05-22 18:51:57|INFO|train.py[:73]|epoch 2, batch 123, loss:2.3810
2022-05-22 18:52:00|INFO|train.py[:73]|epoch 2, batch 124, loss:2.1890
2022-05-22 18:52:03|INFO|train.py[:73]|epoch 2, batch 125, loss:2.7030
2022-05-22 18:52:05|INFO|train.py[:73]|epoch 2, batch 126, loss:2.5361
2022-05-22 18:52:05|INFO|train.py[:81]|epoch 2, batch 126, loss:2.4267
2022-05-22 21:03:07|INFO|train.py[:29]|Start loading data ...
2022-05-22 21:03:07|INFO|train.py[:31]|Data loading is complete, inp len 1000, targ len 1000, which takes 0.001000 s
2022-05-22 21:03:07|INFO|train.py[:37]|Loading text processor...
2022-05-22 21:03:16|INFO|train.py[:73]|epoch 1, batch 1, loss:4.4656
2022-05-22 21:03:19|INFO|train.py[:73]|epoch 1, batch 2, loss:4.5922
